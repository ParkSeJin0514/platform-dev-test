# ============================================================================
# Terraform Destroy (Multi-Cloud: AWS / GCP)
# ============================================================================
# ìˆ˜ë™ ì‹¤í–‰ìœ¼ë¡œ í´ë¼ìš°ë“œì™€ ë ˆì´ì–´ ì„ íƒí•˜ì—¬ Destroy
# - AWS: Karpenter ì •ë¦¬, ALB ì •ë¦¬, Terraform destroy
# - GCP: GKE ì •ë¦¬, Terraform destroy
# ============================================================================

name: Terraform Destroy

on:
  workflow_dispatch:
    inputs:
      cloud:
        description: 'í´ë¼ìš°ë“œ ì„ íƒ'
        required: true
        default: 'aws'
        type: choice
        options:
          - aws
          - gcp
      confirm:
        description: 'ì‚­ì œ í™•ì¸ (destroy ì…ë ¥)'
        required: true
        default: ''
      layer:
        description: 'ì‚­ì œ ë ˆì´ì–´ ì„ íƒ'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - bootstrap
          - compute
          - foundation

env:
  TF_VERSION: '1.9.0'
  TG_VERSION: '0.54.0'
  TERRAGRUNT_IGNORE_DEPENDENCY_ERRORS: "true"

  # AWS ì„¤ì •
  AWS_REGION: ap-northeast-2
  AWS_PROJECT_NAME: "petclinic-kr"

  # GCP ì„¤ì •
  GCP_PROJECT_ID: kdt2-final-project-t1
  GCP_REGION: asia-northeast3
  GCP_CLUSTER_NAME: petclinic-dr-gke
  GCP_WORKLOAD_IDENTITY_PROVIDER: projects/605820610222/locations/global/workloadIdentityPools/github-pool/providers/github-provider

  # Slack
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

permissions:
  id-token: write
  contents: read

jobs:
  # ============================================================================
  # í™•ì¸ ë‹¨ê³„
  # ============================================================================
  confirm:
    name: 'Confirm Destroy'
    runs-on: ubuntu-latest
    steps:
      - name: Check confirmation
        if: github.event.inputs.confirm != 'destroy'
        run: |
          echo "âŒ ì‚­ì œë¥¼ ì§„í–‰í•˜ë ¤ë©´ 'destroy'ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
          exit 1

      - name: Confirmed
        run: |
          echo "âœ… ì‚­ì œê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
          echo "Cloud: ${{ github.event.inputs.cloud }}"
          echo "Layer: ${{ github.event.inputs.layer }}"

  # ============================================================================
  # Slack ì•Œë¦¼ - ìŠ¹ì¸ ìš”ì²­
  # ============================================================================
  notify-approval:
    name: Notify & Wait for Approval
    needs: [confirm]
    runs-on: ubuntu-latest
    steps:
      - name: Send Slack Notification - Approval Request
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "ğŸš¨ Terraform Destroy ìŠ¹ì¸ ìš”ì²­",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Cloud:*\n${{ github.event.inputs.cloud }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Layer:*\n${{ github.event.inputs.layer }}"
                    }
                  ]
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*ì‹¤í–‰ì:*\n${{ github.actor }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*í™•ì¸:*\n${{ github.event.inputs.confirm }}"
                    }
                  ]
                },
                {
                  "type": "context",
                  "elements": [
                    {
                      "type": "mrkdwn",
                      "text": "ğŸ”´ *ê²½ê³ : ì¸í”„ë¼ ì‚­ì œê°€ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤!* ìŠ¹ì¸ í›„ Destroyê°€ ì‹¤í–‰ë©ë‹ˆë‹¤."
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "ìŠ¹ì¸í•˜ëŸ¬ ê°€ê¸°",
                        "emoji": true
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                      "style": "danger"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

  # ============================================================================
  # AWS Pre-Cleanup (ìŠ¹ì¸ í›„, AWS ì„ íƒ ì‹œ)
  # ============================================================================
  aws-pre-cleanup:
    name: 'AWS Pre-Cleanup'
    needs: [notify-approval]
    if: github.event.inputs.cloud == 'aws'
    runs-on: ubuntu-latest
    environment: production  # ğŸ‘ˆ ìŠ¹ì¸ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ëŒ€ê¸°
    timeout-minutes: 15
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl
        id: configure-kubectl
        continue-on-error: true
        run: |
          CLUSTER_NAME=$(aws eks list-clusters --query 'clusters[0]' --output text 2>/dev/null || echo "")
          if [ -n "$CLUSTER_NAME" ] && [ "$CLUSTER_NAME" != "None" ]; then
            aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}
            echo "âœ… EKS í´ëŸ¬ìŠ¤í„° ì—°ê²°: $CLUSTER_NAME"
            echo "cluster_exists=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ EKS í´ëŸ¬ìŠ¤í„° ì—†ìŒ - Pre-cleanup ìŠ¤í‚µ"
            echo "cluster_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup Karpenter Resources
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 8
        run: |
          echo "ğŸ§¹ Karpenter ì •ë¦¬ ì‹œì‘..."

          # ============================================================
          # í•µì‹¬: ArgoCDê°€ Karpenterë¥¼ ë³µêµ¬í•˜ì§€ ëª»í•˜ë„ë¡ ë¨¼ì € ë¹„í™œì„±í™”!
          # ìˆœì„œ: ArgoCD Sync ë¹„í™œì„±í™” â†’ Controller ì¤‘ì§€ â†’ NodePool ì‚­ì œ â†’ EC2 ì¢…ë£Œ
          # ============================================================

          # 0. ArgoCD Karpenter Application Auto-Sync ë¹„í™œì„±í™” (selfHeal ë°©ì§€)
          echo "  0ï¸âƒ£ ArgoCD Karpenter Application Auto-Sync ë¹„í™œì„±í™”..."
          kubectl patch application karpenter -n argocd --type merge \
            -p '{"spec":{"syncPolicy":null}}' 2>/dev/null || true
          kubectl patch application karpenter-config -n argocd --type merge \
            -p '{"spec":{"syncPolicy":null}}' 2>/dev/null || true

          # 1. Karpenter Controller ì¤‘ì§€ (ê°€ì¥ ë¨¼ì €! ìƒˆ ë…¸ë“œ ìƒì„± ë°©ì§€)
          echo "  1ï¸âƒ£ Karpenter Controller ì¤‘ì§€..."
          kubectl scale deployment karpenter -n kube-system --replicas=0 --timeout=60s 2>/dev/null || true

          # Controllerê°€ ì™„ì „íˆ ì¤‘ì§€ë  ë•Œê¹Œì§€ ëŒ€ê¸°
          echo "    Controller ì¤‘ì§€ ëŒ€ê¸° ì¤‘..."
          for i in {1..6}; do
            RUNNING_PODS=$(kubectl get pods -n kube-system -l app.kubernetes.io/name=karpenter --field-selector=status.phase=Running -o name 2>/dev/null | wc -l)
            if [ "$RUNNING_PODS" -eq 0 ]; then
              echo "    âœ… Controller ì¤‘ì§€ ì™„ë£Œ"
              break
            fi
            echo "    ëŒ€ê¸° ì¤‘... ($i/6)"
            sleep 5
          done

          # 2. NodePool ì‚­ì œ (ìƒˆ ë…¸ë“œ ìƒì„± ë°©ì§€ - Controllerê°€ ì¬ì‹œì‘í•´ë„ NodePool ì—†ìœ¼ë©´ ìƒì„± ë¶ˆê°€)
          echo "  2ï¸âƒ£ NodePool ì‚­ì œ..."
          kubectl get nodepools -o name 2>/dev/null | while read np; do
            kubectl patch $np -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $np --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # 3. EC2NodeClass ì‚­ì œ
          echo "  3ï¸âƒ£ EC2NodeClass ì‚­ì œ..."
          kubectl get ec2nodeclasses -o name 2>/dev/null | while read ec; do
            kubectl patch $ec -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $ec --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # 4. NodeClaim Finalizer ì œê±° ë° ì‚­ì œ
          echo "  4ï¸âƒ£ NodeClaim ì‚­ì œ..."
          kubectl get nodeclaims -o name 2>/dev/null | while read nc; do
            kubectl patch $nc -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $nc --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # 5. EC2 ì¸ìŠ¤í„´ìŠ¤ ê°•ì œ ì¢…ë£Œ (Controller ì¤‘ì§€ í›„ ì•ˆì „í•˜ê²Œ ì¢…ë£Œ)
          echo "  5ï¸âƒ£ Karpenter EC2 ì¸ìŠ¤í„´ìŠ¤ ê°•ì œ ì¢…ë£Œ..."
          KARPENTER_INSTANCES=$(aws ec2 describe-instances \
            --filters "Name=tag:karpenter.sh/nodepool,Values=*" "Name=instance-state-name,Values=running,pending,stopping" \
            --query 'Reservations[*].Instances[*].InstanceId' --output text 2>/dev/null || true)
          if [ -n "$KARPENTER_INSTANCES" ]; then
            echo "    ì¢…ë£Œí•  ì¸ìŠ¤í„´ìŠ¤: $KARPENTER_INSTANCES"
            aws ec2 terminate-instances --instance-ids $KARPENTER_INSTANCES 2>/dev/null || true
          else
            echo "    Karpenter EC2 ì¸ìŠ¤í„´ìŠ¤ ì—†ìŒ"
          fi

          # 6. Karpenter ë…¸ë“œ ì‚­ì œ (K8sì—ì„œ ë…¸ë“œ ê°ì²´ ì œê±°)
          echo "  6ï¸âƒ£ Karpenter ë…¸ë“œ ì‚­ì œ..."
          KARPENTER_NODES=$(kubectl get nodes -l karpenter.sh/nodepool -o name 2>/dev/null || true)
          if [ -n "$KARPENTER_NODES" ]; then
            echo "$KARPENTER_NODES" | while read node; do
              echo "    ì‚­ì œ ì¤‘: $node"
              kubectl delete $node --force --grace-period=0 --timeout=60s 2>/dev/null || true
            done
          else
            echo "    Karpenter ë…¸ë“œ ì—†ìŒ"
          fi

          # 7. EC2 ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ í™•ì¸ (ìµœëŒ€ 2ë¶„ ëŒ€ê¸°)
          echo "  7ï¸âƒ£ EC2 ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ í™•ì¸..."
          for i in {1..12}; do
            REMAINING=$(aws ec2 describe-instances \
              --filters "Name=tag:karpenter.sh/nodepool,Values=*" "Name=instance-state-name,Values=running,pending,stopping,shutting-down" \
              --query 'Reservations[*].Instances[*].InstanceId' --output text 2>/dev/null || true)
            if [ -z "$REMAINING" ]; then
              echo "    âœ… ëª¨ë“  Karpenter ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ ì™„ë£Œ"
              break
            fi
            echo "    ëŒ€ê¸° ì¤‘... ($i/12) - ë‚¨ì€ ì¸ìŠ¤í„´ìŠ¤: $REMAINING"
            sleep 10
          done

          # 8. í˜¹ì‹œ ë‚¨ì€ ì¸ìŠ¤í„´ìŠ¤ í•œë²ˆ ë” ì¢…ë£Œ ì‹œë„
          FINAL_CHECK=$(aws ec2 describe-instances \
            --filters "Name=tag:karpenter.sh/nodepool,Values=*" "Name=instance-state-name,Values=running,pending" \
            --query 'Reservations[*].Instances[*].InstanceId' --output text 2>/dev/null || true)
          if [ -n "$FINAL_CHECK" ]; then
            echo "  âš ï¸ ë‚¨ì€ ì¸ìŠ¤í„´ìŠ¤ ì¬ì¢…ë£Œ: $FINAL_CHECK"
            aws ec2 terminate-instances --instance-ids $FINAL_CHECK 2>/dev/null || true
          fi

          echo "âœ… Karpenter ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup ArgoCD Applications
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 2
        run: |
          echo "ğŸ§¹ ArgoCD ì •ë¦¬ ì‹œì‘..."

          # Application Finalizer ì œê±° ë° ì‚­ì œ
          kubectl get applications -n argocd -o name 2>/dev/null | while read app; do
            kubectl patch $app -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $app -n argocd --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          echo "âœ… ArgoCD ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup Ingress and LoadBalancer Services
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 3
        run: |
          echo "ğŸ§¹ Ingress ë° LoadBalancer ì •ë¦¬ ì‹œì‘..."

          # ëª¨ë“  Ingress ì‚­ì œ
          kubectl get ingress -A -o json 2>/dev/null | jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl patch ingress $name -n $ns -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete ingress $name -n $ns --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # LoadBalancer íƒ€ì… Service ì‚­ì œ
          kubectl get svc -A -o json 2>/dev/null | jq -r '.items[] | select(.spec.type=="LoadBalancer") | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl delete svc $name -n $ns --timeout=60s 2>/dev/null || true
          done

          echo "âœ… Ingress ë° LoadBalancer ì •ë¦¬ ì™„ë£Œ"

      - name: Force Delete ALB and Target Groups
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 5
        run: |
          echo "ğŸ§¹ ALB ë° Target Group ê°•ì œ ì‚­ì œ..."

          # petclinic ê´€ë ¨ ALB ê°•ì œ ì‚­ì œ
          for alb_arn in $(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'petclinic') || contains(LoadBalancerName, 'k8s') || contains(LoadBalancerName, 'argocd')].LoadBalancerArn" --output text 2>/dev/null); do
            echo "  ì‚­ì œ ì¤‘: $alb_arn"
            # Listener ë¨¼ì € ì‚­ì œ
            for listener_arn in $(aws elbv2 describe-listeners --load-balancer-arn $alb_arn --query 'Listeners[*].ListenerArn' --output text 2>/dev/null); do
              aws elbv2 delete-listener --listener-arn $listener_arn 2>/dev/null || true
            done
            # ALB ì‚­ì œ
            aws elbv2 delete-load-balancer --load-balancer-arn $alb_arn 2>/dev/null || true
          done

          echo "â³ ALB ì‚­ì œ ëŒ€ê¸° (30ì´ˆ)..."
          sleep 30

          # ê³ ì•„ Target Group ì‚­ì œ
          echo "ğŸ§¹ ê³ ì•„ Target Group ì‚­ì œ..."
          for tg_arn in $(aws elbv2 describe-target-groups --query "TargetGroups[?contains(TargetGroupName, 'k8s') || contains(TargetGroupName, 'petclinic')].TargetGroupArn" --output text 2>/dev/null); do
            echo "  ì‚­ì œ ì¤‘: $tg_arn"
            aws elbv2 delete-target-group --target-group-arn $tg_arn 2>/dev/null || true
          done

          echo "âœ… ALB ë° Target Group ì •ë¦¬ ì™„ë£Œ"

      - name: Wait for ALB Deletion
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 5
        run: |
          echo "â³ AWS ë¡œë“œë°¸ëŸ°ì„œ ì‚­ì œ í™•ì¸..."

          # ALB ì‚­ì œ í™•ì¸ (ìµœëŒ€ 5ë¶„ ëŒ€ê¸°)
          for i in {1..30}; do
            ALB_COUNT=$(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'k8s') || contains(LoadBalancerName, 'argocd') || contains(LoadBalancerName, 'petclinic')].LoadBalancerArn" --output text 2>/dev/null | wc -w || echo "0")
            if [ "$ALB_COUNT" -eq 0 ]; then
              echo "âœ… ëª¨ë“  ALB ì‚­ì œ ì™„ë£Œ"
              break
            fi
            echo "  ëŒ€ê¸° ì¤‘... ($i/30) - ë‚¨ì€ ALB: $ALB_COUNT"
            sleep 10
          done

      - name: Pre-Cleanup Complete
        run: echo "âœ… AWS Pre-Cleanup ì™„ë£Œ"

  # ============================================================================
  # GCP Pre-Cleanup (ìŠ¹ì¸ í›„, GCP ì„ íƒ ì‹œ)
  # ============================================================================
  gcp-pre-cleanup:
    name: 'GCP Pre-Cleanup'
    needs: [notify-approval]
    if: github.event.inputs.cloud == 'gcp'
    runs-on: ubuntu-latest
    environment: production  # ğŸ‘ˆ ìŠ¹ì¸ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ëŒ€ê¸°
    timeout-minutes: 15
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: github-actions@${{ env.GCP_PROJECT_ID }}.iam.gserviceaccount.com

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl
        id: configure-kubectl
        continue-on-error: true
        run: |
          if gcloud container clusters describe ${{ env.GCP_CLUSTER_NAME }} --region ${{ env.GCP_REGION }} 2>/dev/null; then
            gcloud container clusters get-credentials ${{ env.GCP_CLUSTER_NAME }} \
              --region ${{ env.GCP_REGION }} \
              --project ${{ env.GCP_PROJECT_ID }}
            echo "âœ… GKE í´ëŸ¬ìŠ¤í„° ì—°ê²°: ${{ env.GCP_CLUSTER_NAME }}"
            echo "cluster_exists=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ GKE í´ëŸ¬ìŠ¤í„° ì—†ìŒ - Pre-cleanup ìŠ¤í‚µ"
            echo "cluster_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup ArgoCD Applications
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 2
        run: |
          echo "ğŸ§¹ ArgoCD ì •ë¦¬ ì‹œì‘..."

          kubectl get applications -n argocd -o name 2>/dev/null | while read app; do
            kubectl patch $app -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $app -n argocd --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          echo "âœ… ArgoCD ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup Ingress and LoadBalancer Services
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 2
        run: |
          echo "ğŸ§¹ Ingress ë° LoadBalancer ì •ë¦¬ ì‹œì‘..."

          # ëª¨ë“  Ingress ì‚­ì œ
          kubectl get ingress -A -o json 2>/dev/null | jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl patch ingress $name -n $ns -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete ingress $name -n $ns --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # LoadBalancer íƒ€ì… Service ì‚­ì œ
          kubectl get svc -A -o json 2>/dev/null | jq -r '.items[] | select(.spec.type=="LoadBalancer") | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl delete svc $name -n $ns --timeout=60s 2>/dev/null || true
          done

          echo "âœ… Ingress ë° LoadBalancer ì •ë¦¬ ì™„ë£Œ"

          # GKE Ingress Controllerê°€ LB ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•  ì‹œê°„ ëŒ€ê¸°
          echo "â³ GKE Ingress Controllerê°€ LB ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘... (60ì´ˆ ëŒ€ê¸°)"
          sleep 60

      - name: Cleanup GKE Ingress Resources (LB Stack â†’ Backend â†’ NEG)
        continue-on-error: true
        timeout-minutes: 8
        run: |
          echo "ğŸ§¹ GKE Ingress ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘ (GKE Controllerê°€ ëª» ì§€ìš´ ì”ì—¬ë¬¼ ì •ë¦¬)..."
          echo "   ì‚­ì œ ìˆœì„œ: Forwarding Rules â†’ Target Proxies â†’ URL Maps â†’ Backend Services â†’ Health Checks â†’ NEG â†’ Firewall"

          # ============================================================
          # GKE Ingress ì‚­ì œ ìˆœì„œ (ì—­ìˆœìœ¼ë¡œ ì‚­ì œí•´ì•¼ ì˜ì¡´ì„± í•´ê²°)
          # Ingress â†’ Forwarding Rule â†’ Target Proxy â†’ URL Map â†’ Backend Service â†’ Health Check â†’ NEG
          # ============================================================

          # 1. Forwarding Rules ì‚­ì œ (ê°€ì¥ ë¨¼ì € - LBì˜ ìµœìƒìœ„ ë¦¬ì†ŒìŠ¤)
          echo "  1ï¸âƒ£ Forwarding Rules ì‚­ì œ..."
          for fr in $(gcloud compute forwarding-rules list --filter="name~k8s OR name~tf-" --format="value(name)" --global 2>/dev/null); do
            echo "    ì‚­ì œ: $fr"
            gcloud compute forwarding-rules delete "$fr" --global --quiet 2>/dev/null || true
          done

          # 2. Target HTTP/HTTPS Proxies ì‚­ì œ
          echo "  2ï¸âƒ£ Target HTTP Proxies ì‚­ì œ..."
          for proxy in $(gcloud compute target-http-proxies list --filter="name~k8s OR name~tf-" --format="value(name)" 2>/dev/null); do
            echo "    ì‚­ì œ: $proxy"
            gcloud compute target-http-proxies delete "$proxy" --global --quiet 2>/dev/null || true
          done
          echo "  2ï¸âƒ£ Target HTTPS Proxies ì‚­ì œ..."
          for proxy in $(gcloud compute target-https-proxies list --filter="name~k8s OR name~tf-" --format="value(name)" 2>/dev/null); do
            echo "    ì‚­ì œ: $proxy"
            gcloud compute target-https-proxies delete "$proxy" --global --quiet 2>/dev/null || true
          done

          # 3. URL Maps ì‚­ì œ
          echo "  3ï¸âƒ£ URL Maps ì‚­ì œ..."
          for um in $(gcloud compute url-maps list --filter="name~k8s OR name~tf-" --format="value(name)" 2>/dev/null); do
            echo "    ì‚­ì œ: $um"
            gcloud compute url-maps delete "$um" --global --quiet 2>/dev/null || true
          done

          # 4. Backend Services ì‚­ì œ (NEGë¥¼ ì°¸ì¡°í•˜ë¯€ë¡œ NEG ì‚­ì œ ì „ì— ì‚­ì œ í•„ìˆ˜!)
          echo "  4ï¸âƒ£ Backend Services ì‚­ì œ..."
          for bs in $(gcloud compute backend-services list --filter="name~k8s OR name~tf-" --format="value(name)" --global 2>/dev/null); do
            echo "    ì‚­ì œ: $bs"
            gcloud compute backend-services delete "$bs" --global --quiet 2>/dev/null || true
          done

          # 5. Health Checks ì‚­ì œ
          echo "  5ï¸âƒ£ Health Checks ì‚­ì œ..."
          for hc in $(gcloud compute health-checks list --filter="name~k8s" --format="value(name)" 2>/dev/null); do
            echo "    ì‚­ì œ: $hc"
            gcloud compute health-checks delete "$hc" --global --quiet 2>/dev/null || true
          done

          # 6. Network Endpoint Groups (NEG) ì‚­ì œ - Backend Service ì‚­ì œ í›„ì—ë§Œ ê°€ëŠ¥!
          echo "  6ï¸âƒ£ Network Endpoint Groups ì‚­ì œ..."
          # ëª¨ë“  k8s ê´€ë ¨ NEG ì‚­ì œ (k8s1-*, k8s2-*, petclinic-*)
          for zone in $(gcloud compute zones list --filter="region:${{ env.GCP_REGION }}" --format="value(name)" 2>/dev/null); do
            for neg in $(gcloud compute network-endpoint-groups list --filter="zone:$zone AND (name~k8s1 OR name~k8s2 OR name~petclinic)" --format="value(name)" 2>/dev/null); do
              echo "    ì‚­ì œ: $neg (zone: $zone)"
              gcloud compute network-endpoint-groups delete "$neg" --zone="$zone" --quiet 2>/dev/null || true
            done
          done

          # 7. GKEê°€ ìƒì„±í•œ ë°©í™”ë²½ ê·œì¹™ ì‚­ì œ (k8s-fw-* íŒ¨í„´)
          echo "  7ï¸âƒ£ GKE ë°©í™”ë²½ ê·œì¹™ ì‚­ì œ..."
          for fw in $(gcloud compute firewall-rules list --filter="name~k8s" --format="value(name)" 2>/dev/null); do
            echo "    ì‚­ì œ: $fw"
            gcloud compute firewall-rules delete "$fw" --quiet 2>/dev/null || true
          done

          # NEG ì‚­ì œ í™•ì¸ (ìµœëŒ€ 1ë¶„ ëŒ€ê¸°)
          echo "  â³ NEG ì‚­ì œ í™•ì¸..."
          for i in {1..6}; do
            REMAINING=$(gcloud compute network-endpoint-groups list --filter="name~k8s1 OR name~k8s2 OR name~petclinic" --format="value(name)" 2>/dev/null | wc -l)
            if [ "$REMAINING" -eq 0 ]; then
              echo "  âœ… ëª¨ë“  NEG ì‚­ì œ ì™„ë£Œ"
              break
            fi
            echo "    ëŒ€ê¸° ì¤‘... ($i/6) - ë‚¨ì€ NEG: $REMAINING"
            # ë‚¨ì€ NEG ì¬ì‹œë„ ì‚­ì œ
            for zone in $(gcloud compute zones list --filter="region:${{ env.GCP_REGION }}" --format="value(name)" 2>/dev/null); do
              for neg in $(gcloud compute network-endpoint-groups list --filter="zone:$zone AND (name~k8s1 OR name~k8s2 OR name~petclinic)" --format="value(name)" 2>/dev/null); do
                gcloud compute network-endpoint-groups delete "$neg" --zone="$zone" --quiet 2>/dev/null || true
              done
            done
            sleep 10
          done

          echo "âœ… GKE Ingress ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ"

      - name: Delete Cloud SQL Instance (Must be deleted before VPC Peering)
        continue-on-error: true
        timeout-minutes: 10
        run: |
          echo "ğŸ§¹ Cloud SQL ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ (VPC Peering ì‚­ì œ ì „ í•„ìˆ˜)..."

          # Cloud SQL ì¸ìŠ¤í„´ìŠ¤ ëª©ë¡ ì¡°íšŒ ë° ì‚­ì œ
          for instance in $(gcloud sql instances list --filter="name~petclinic" --format="value(name)" 2>/dev/null); do
            echo "  Cloud SQL ì‚­ì œ: $instance"
            # deletion protection í•´ì œ
            gcloud sql instances patch "$instance" --no-deletion-protection --quiet 2>/dev/null || true
            # ì¸ìŠ¤í„´ìŠ¤ ì‚­ì œ
            gcloud sql instances delete "$instance" --quiet 2>/dev/null || true
          done

          # Cloud SQL ì‚­ì œ ëŒ€ê¸° (ìµœëŒ€ 8ë¶„ - Cloud SQL ì‚­ì œëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¼)
          echo "  Cloud SQL ì‚­ì œ ëŒ€ê¸°..."
          for i in {1..48}; do
            REMAINING=$(gcloud sql instances list --filter="name~petclinic" --format="value(name)" 2>/dev/null | wc -l)
            if [ "$REMAINING" -eq 0 ]; then
              echo "  âœ… Cloud SQL ì‚­ì œ ì™„ë£Œ"
              break
            fi
            echo "    ëŒ€ê¸° ì¤‘... ($i/48) - ë‚¨ì€ ì¸ìŠ¤í„´ìŠ¤: $REMAINING"
            sleep 10
          done

          # ìµœì¢… í™•ì¸
          FINAL_CHECK=$(gcloud sql instances list --filter="name~petclinic" --format="value(name)" 2>/dev/null | wc -l)
          if [ "$FINAL_CHECK" -gt 0 ]; then
            echo "  âš ï¸ Cloud SQL ì¸ìŠ¤í„´ìŠ¤ê°€ ì•„ì§ ì‚­ì œ ì¤‘ì…ë‹ˆë‹¤. Terraformì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤."
          fi

          echo "âœ… Cloud SQL ì •ë¦¬ ì™„ë£Œ"

      - name: Final Cleanup - NEG and Firewall (Before VPC deletion)
        continue-on-error: true
        timeout-minutes: 5
        run: |
          echo "ğŸ§¹ VPC ì‚­ì œ ì „ NEG ë° ë°©í™”ë²½ ê·œì¹™ ìµœì¢… ì •ë¦¬..."

          # ============================================================
          # NEG ìµœì¢… ì •ë¦¬ (GKE ì‚­ì œ í›„ì—ë„ ë‚¨ì•„ìˆì„ ìˆ˜ ìˆìŒ)
          # k8s1-*, k8s2-*, petclinic-* íŒ¨í„´: GKEê°€ ìƒì„±í•œ NEG
          # ============================================================
          echo "  1ï¸âƒ£ ë‚¨ì€ NEG ìµœì¢… ì‚­ì œ..."
          # ëª¨ë“  k8s ê´€ë ¨ NEG ì‚­ì œ (k8s1-*, k8s2-*, petclinic-*)
          for zone in $(gcloud compute zones list --filter="region:${{ env.GCP_REGION }}" --format="value(name)" 2>/dev/null); do
            for neg in $(gcloud compute network-endpoint-groups list --filter="zone:$zone AND (name~k8s1 OR name~k8s2 OR name~petclinic)" --format="value(name)" 2>/dev/null); do
              echo "    ì‚­ì œ: $neg (zone: $zone)"
              gcloud compute network-endpoint-groups delete "$neg" --zone="$zone" --quiet 2>/dev/null || true
            done
          done

          # NEG ì‚­ì œ í™•ì¸ (ìµœëŒ€ 1ë¶„ ëŒ€ê¸°)
          echo "  â³ NEG ì‚­ì œ í™•ì¸..."
          for i in {1..6}; do
            REMAINING=$(gcloud compute network-endpoint-groups list --filter="name~k8s1 OR name~k8s2 OR name~petclinic" --format="value(name)" 2>/dev/null | wc -l)
            if [ "$REMAINING" -eq 0 ]; then
              echo "  âœ… ëª¨ë“  NEG ì‚­ì œ ì™„ë£Œ"
              break
            fi
            echo "    ëŒ€ê¸° ì¤‘... ($i/6) - ë‚¨ì€ NEG: $REMAINING"
            for zone in $(gcloud compute zones list --filter="region:${{ env.GCP_REGION }}" --format="value(name)" 2>/dev/null); do
              for neg in $(gcloud compute network-endpoint-groups list --filter="zone:$zone AND (name~k8s1 OR name~k8s2 OR name~petclinic)" --format="value(name)" 2>/dev/null); do
                gcloud compute network-endpoint-groups delete "$neg" --zone="$zone" --quiet 2>/dev/null || true
              done
            done
            sleep 10
          done

          # ============================================================
          # ë°©í™”ë²½ ê·œì¹™ ìµœì¢… ì •ë¦¬
          # ============================================================
          echo "  2ï¸âƒ£ ë°©í™”ë²½ ê·œì¹™ ìµœì¢… ì‚­ì œ..."

          # VPC ì´ë¦„ ì¡°íšŒ
          VPCS=$(gcloud compute networks list --filter="name~petclinic" --format="value(name)" 2>/dev/null || true)

          for vpc in $VPCS; do
            echo "  VPC: $vpcì˜ ë°©í™”ë²½ ê·œì¹™ ì‚­ì œ..."

            # í•´ë‹¹ VPCì˜ ëª¨ë“  ë°©í™”ë²½ ê·œì¹™ ì‚­ì œ (k8s íŒ¨í„´ + í•´ë‹¹ VPCì— ì—°ê²°ëœ ëª¨ë“  ê·œì¹™)
            for fw in $(gcloud compute firewall-rules list --filter="network:$vpc" --format="value(name)" 2>/dev/null); do
              echo "    ì‚­ì œ: $fw"
              gcloud compute firewall-rules delete "$fw" --quiet 2>/dev/null || true
            done
          done

          # k8s íŒ¨í„´ ë°©í™”ë²½ ê·œì¹™ í•œë²ˆ ë” ì‚­ì œ (VPC í•„í„° ì—†ì´)
          echo "  k8s íŒ¨í„´ ë°©í™”ë²½ ê·œì¹™ ì‚­ì œ..."
          for fw in $(gcloud compute firewall-rules list --filter="name~k8s" --format="value(name)" 2>/dev/null); do
            echo "    ì‚­ì œ: $fw"
            gcloud compute firewall-rules delete "$fw" --quiet 2>/dev/null || true
          done

          # ë°©í™”ë²½ ì‚­ì œ í™•ì¸ ëŒ€ê¸° (ìµœëŒ€ 30ì´ˆ)
          echo "  â³ ë°©í™”ë²½ ì‚­ì œ í™•ì¸..."
          for i in {1..6}; do
            REMAINING=$(gcloud compute firewall-rules list --filter="name~k8s OR network~petclinic" --format="value(name)" 2>/dev/null | wc -l)
            if [ "$REMAINING" -eq 0 ]; then
              echo "  âœ… ëª¨ë“  ë°©í™”ë²½ ê·œì¹™ ì‚­ì œ ì™„ë£Œ"
              break
            fi
            echo "    ëŒ€ê¸° ì¤‘... ($i/6) - ë‚¨ì€ ê·œì¹™: $REMAINING"
            sleep 5
          done

          echo "âœ… NEG ë° ë°©í™”ë²½ ê·œì¹™ ìµœì¢… ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup VPC Resources (Peering, Routes, Addresses)
        continue-on-error: true
        timeout-minutes: 5
        run: |
          echo "ğŸ§¹ VPC ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì‹œì‘..."

          # ============================================================
          # Cloud SQL ì‚­ì œ ì™„ë£Œ í™•ì¸ (Service Networking Connection ì‚­ì œ ì „ í•„ìˆ˜!)
          # ============================================================
          echo "  0ï¸âƒ£ Cloud SQL ì‚­ì œ ì™„ë£Œ í™•ì¸..."
          for i in {1..12}; do
            SQL_COUNT=$(gcloud sql instances list --filter="name~petclinic" --format="value(name)" 2>/dev/null | wc -l)
            if [ "$SQL_COUNT" -eq 0 ]; then
              echo "  âœ… Cloud SQL ì‚­ì œ í™•ì¸ë¨"
              break
            fi
            echo "    Cloud SQL ì•„ì§ ì‚­ì œ ì¤‘... ($i/12)"
            sleep 10
          done

          # petclinic ê´€ë ¨ VPC ëª©ë¡ ì¡°íšŒ
          VPCS=$(gcloud compute networks list --filter="name~petclinic" --format="value(name)" 2>/dev/null || true)

          for vpc in $VPCS; do
            echo "  VPC: $vpc"

            # 1. Service Networking Connection ì‚­ì œ (Cloud SQL Private Service Connection)
            echo "    Service Networking Connection ì‚­ì œ..."
            # Cloud SQLì´ ì•„ì§ ì‚­ì œ ì¤‘ì´ë©´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¬ì‹œë„
            for retry in {1..3}; do
              gcloud services vpc-peerings delete \
                --service=servicenetworking.googleapis.com \
                --network=$vpc \
                --quiet 2>/dev/null && break
              echo "    Service Networking ì‚­ì œ ì¬ì‹œë„... ($retry/3)"
              sleep 10
            done

            # 2. VPC Peering ì‚­ì œ
            PEERINGS=$(gcloud compute networks peerings list --network=$vpc --format="value(name)" 2>/dev/null || true)
            for peering in $PEERINGS; do
              echo "    Peering ì‚­ì œ: $peering"
              gcloud compute networks peerings delete $peering --network=$vpc --quiet 2>/dev/null || true
            done

            # 3. VPCì— ì—°ê²°ëœ Route ì‚­ì œ
            ROUTES=$(gcloud compute routes list --filter="network:$vpc" --format="value(name)" 2>/dev/null || true)
            for route in $ROUTES; do
              echo "    Route ì‚­ì œ: $route"
              gcloud compute routes delete $route --quiet 2>/dev/null || true
            done
          done

          # 4. Global Address ì‚­ì œ (Cloud SQL Private IP ë“±)
          echo "  Global Address ì‚­ì œ..."
          for addr in $(gcloud compute addresses list --filter="name~petclinic" --format="value(name)" --global 2>/dev/null); do
            echo "    ì‚­ì œ: $addr"
            gcloud compute addresses delete "$addr" --global --quiet 2>/dev/null || true
          done

          echo "âœ… VPC ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ"

      - name: Pre-Cleanup Complete
        run: echo "âœ… GCP Pre-Cleanup ì™„ë£Œ"

  # ============================================================================
  # Terraform Destroy (ìŠ¹ì¸ ë° Pre-Cleanup í›„ ì‹¤í–‰)
  # ============================================================================
  destroy:
    name: 'Terraform Destroy'
    needs: [notify-approval, aws-pre-cleanup, gcp-pre-cleanup]
    if: always() && needs.notify-approval.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 60

    defaults:
      run:
        working-directory: ${{ github.event.inputs.cloud }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # AWS ì¸ì¦
      - name: Configure AWS credentials
        if: github.event.inputs.cloud == 'aws'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      # GCP ì¸ì¦
      - name: Authenticate to Google Cloud
        if: github.event.inputs.cloud == 'gcp'
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: github-actions@${{ env.GCP_PROJECT_ID }}.iam.gserviceaccount.com

      - name: Set up Cloud SDK
        if: github.event.inputs.cloud == 'gcp'
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: Setup Terragrunt
        run: |
          wget -q https://github.com/gruntwork-io/terragrunt/releases/download/v${{ env.TG_VERSION }}/terragrunt_linux_amd64
          chmod +x terragrunt_linux_amd64
          sudo mv terragrunt_linux_amd64 /usr/local/bin/terragrunt

      # SSH Key (AWS ì „ìš©)
      - name: Create SSH Key
        if: github.event.inputs.cloud == 'aws'
        run: |
          mkdir -p keys
          echo "${{ secrets.SSH_PUBLIC_KEY }}" > keys/test.pub

      # Destroy Compute (EKS/GKE ë¨¼ì € ì‚­ì œ - ë‚´ë¶€ ë¦¬ì†ŒìŠ¤ ìë™ ì •ë¦¬)
      - name: Destroy Compute
        if: github.event.inputs.layer == 'all' || github.event.inputs.layer == 'compute'
        continue-on-error: true
        timeout-minutes: 30
        env:
          TF_VAR_db_password: ${{ secrets.TF_VAR_db_password }}
        run: |
          echo "ğŸ—‘ï¸ Compute Layer Destroy (EKS/GKE ë¨¼ì € ì‚­ì œ)..."
          cd compute && terragrunt destroy --terragrunt-non-interactive -auto-approve || true

      # Destroy Bootstrap (EKS ì‚­ì œ í›„ ì‹¤í–‰ - ArgoCD ë“± ë‚´ë¶€ ë¦¬ì†ŒìŠ¤ëŠ” ì´ë¯¸ ì •ë¦¬ë¨)
      - name: Destroy Bootstrap
        if: github.event.inputs.layer == 'all' || github.event.inputs.layer == 'bootstrap'
        continue-on-error: true
        timeout-minutes: 15
        env:
          TF_VAR_db_password: ${{ secrets.TF_VAR_db_password }}
        run: |
          echo "ğŸ—‘ï¸ Bootstrap Layer Destroy..."
          cd bootstrap && terragrunt destroy --terragrunt-non-interactive -auto-approve || true

      # Destroy Foundation
      - name: Destroy Foundation
        if: github.event.inputs.layer == 'all' || github.event.inputs.layer == 'foundation'
        continue-on-error: true
        timeout-minutes: 15
        env:
          TF_VAR_db_password: ${{ secrets.TF_VAR_db_password }}
        run: |
          echo "ğŸ—‘ï¸ Foundation Layer Destroy..."
          cd foundation && terragrunt destroy --terragrunt-non-interactive -auto-approve || true

      - name: Destroy Complete
        run: |
          echo "=============================================="
          echo "ğŸ‰ Terraform Destroy ì™„ë£Œ!"
          echo "=============================================="
          echo "Cloud: ${{ github.event.inputs.cloud }}"
          echo "Layer: ${{ github.event.inputs.layer }}"

  # ============================================
  # Slack ì•Œë¦¼ - ì™„ë£Œ
  # ============================================
  notify-complete:
    needs: [destroy]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Send Slack Notification - Complete
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "${{ needs.destroy.result == 'success' && 'âœ… Terraform Destroy ì„±ê³µ' || 'âŒ Terraform Destroy ì‹¤íŒ¨' }}",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Cloud:*\n${{ github.event.inputs.cloud }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Layer:*\n${{ github.event.inputs.layer }}"
                    }
                  ]
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*ê²°ê³¼:*\n${{ needs.destroy.result }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*ì‹¤í–‰ì:*\n${{ github.actor }}"
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "ìƒì„¸ ë¡œê·¸ ë³´ê¸°",
                        "emoji": true
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

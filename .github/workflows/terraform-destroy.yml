# ============================================================================
# Terraform Destroy (Multi-Cloud: AWS / GCP)
# ============================================================================
# ìˆ˜ë™ ì‹¤í–‰ìœ¼ë¡œ í´ë¼ìš°ë“œì™€ ë ˆì´ì–´ ì„ íƒí•˜ì—¬ Destroy
# - AWS: Karpenter ì •ë¦¬, ALB ì •ë¦¬, Terraform destroy
# - GCP: GKE ì •ë¦¬, Terraform destroy
# ============================================================================

name: Terraform Destroy

on:
  workflow_dispatch:
    inputs:
      cloud:
        description: 'í´ë¼ìš°ë“œ ì„ íƒ'
        required: true
        default: 'aws'
        type: choice
        options:
          - aws
          - gcp
      confirm:
        description: 'ì‚­ì œ í™•ì¸ (destroy ì…ë ¥)'
        required: true
        default: ''
      layer:
        description: 'ì‚­ì œ ë ˆì´ì–´ ì„ íƒ'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - bootstrap
          - compute
          - foundation

env:
  TF_VERSION: '1.9.0'
  TG_VERSION: '0.54.0'
  TERRAGRUNT_IGNORE_DEPENDENCY_ERRORS: "true"

  # AWS ì„¤ì •
  AWS_REGION: ap-northeast-2
  AWS_PROJECT_NAME: "petclinic-kr"

  # GCP ì„¤ì •
  GCP_PROJECT_ID: kdt2-final-project-t1
  GCP_REGION: asia-northeast3
  GCP_CLUSTER_NAME: petclinic-dr-gke
  GCP_WORKLOAD_IDENTITY_PROVIDER: projects/605820610222/locations/global/workloadIdentityPools/github-pool/providers/github-provider

  # Slack
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}

permissions:
  id-token: write
  contents: read

jobs:
  # ============================================================================
  # í™•ì¸ ë‹¨ê³„
  # ============================================================================
  confirm:
    name: 'Confirm Destroy'
    runs-on: ubuntu-latest
    steps:
      - name: Check confirmation
        if: github.event.inputs.confirm != 'destroy'
        run: |
          echo "âŒ ì‚­ì œë¥¼ ì§„í–‰í•˜ë ¤ë©´ 'destroy'ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
          exit 1

      - name: Confirmed
        run: |
          echo "âœ… ì‚­ì œê°€ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤."
          echo "Cloud: ${{ github.event.inputs.cloud }}"
          echo "Layer: ${{ github.event.inputs.layer }}"

  # ============================================================================
  # Slack ì•Œë¦¼ - ìŠ¹ì¸ ìš”ì²­
  # ============================================================================
  notify-approval:
    name: Notify & Wait for Approval
    needs: [confirm]
    runs-on: ubuntu-latest
    steps:
      - name: Send Slack Notification - Approval Request
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "ğŸš¨ Terraform Destroy ìŠ¹ì¸ ìš”ì²­",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Cloud:*\n${{ github.event.inputs.cloud }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Layer:*\n${{ github.event.inputs.layer }}"
                    }
                  ]
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*ì‹¤í–‰ì:*\n${{ github.actor }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*í™•ì¸:*\n${{ github.event.inputs.confirm }}"
                    }
                  ]
                },
                {
                  "type": "context",
                  "elements": [
                    {
                      "type": "mrkdwn",
                      "text": "ğŸ”´ *ê²½ê³ : ì¸í”„ë¼ ì‚­ì œê°€ ìš”ì²­ë˜ì—ˆìŠµë‹ˆë‹¤!* ìŠ¹ì¸ í›„ Destroyê°€ ì‹¤í–‰ë©ë‹ˆë‹¤."
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "ìŠ¹ì¸í•˜ëŸ¬ ê°€ê¸°",
                        "emoji": true
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                      "style": "danger"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK

  # ============================================================================
  # AWS Pre-Cleanup (ìŠ¹ì¸ í›„, AWS ì„ íƒ ì‹œ)
  # ============================================================================
  aws-pre-cleanup:
    name: 'AWS Pre-Cleanup'
    needs: [notify-approval]
    if: github.event.inputs.cloud == 'aws'
    runs-on: ubuntu-latest
    environment: production  # ğŸ‘ˆ ìŠ¹ì¸ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ëŒ€ê¸°
    timeout-minutes: 15
    steps:
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl
        id: configure-kubectl
        continue-on-error: true
        run: |
          CLUSTER_NAME=$(aws eks list-clusters --query 'clusters[0]' --output text 2>/dev/null || echo "")
          if [ -n "$CLUSTER_NAME" ] && [ "$CLUSTER_NAME" != "None" ]; then
            aws eks update-kubeconfig --name $CLUSTER_NAME --region ${{ env.AWS_REGION }}
            echo "âœ… EKS í´ëŸ¬ìŠ¤í„° ì—°ê²°: $CLUSTER_NAME"
            echo "cluster_exists=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ EKS í´ëŸ¬ìŠ¤í„° ì—†ìŒ - Pre-cleanup ìŠ¤í‚µ"
            echo "cluster_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup Karpenter Resources
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 3
        run: |
          echo "ğŸ§¹ Karpenter ì •ë¦¬ ì‹œì‘..."

          # Karpenter Controller ì¤‘ì§€
          kubectl scale deployment karpenter -n kube-system --replicas=0 --timeout=30s 2>/dev/null || true

          # NodeClaim Finalizer ì œê±° ë° ì‚­ì œ
          kubectl get nodeclaims -o name 2>/dev/null | while read nc; do
            kubectl patch $nc -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $nc --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # NodePool Finalizer ì œê±° ë° ì‚­ì œ
          kubectl get nodepools -o name 2>/dev/null | while read np; do
            kubectl patch $np -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $np --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # EC2NodeClass Finalizer ì œê±° ë° ì‚­ì œ
          kubectl get ec2nodeclasses -o name 2>/dev/null | while read ec; do
            kubectl patch $ec -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $ec --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          echo "âœ… Karpenter ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup ArgoCD Applications
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 2
        run: |
          echo "ğŸ§¹ ArgoCD ì •ë¦¬ ì‹œì‘..."

          # Application Finalizer ì œê±° ë° ì‚­ì œ
          kubectl get applications -n argocd -o name 2>/dev/null | while read app; do
            kubectl patch $app -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $app -n argocd --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          echo "âœ… ArgoCD ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup Ingress and LoadBalancer Services
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 3
        run: |
          echo "ğŸ§¹ Ingress ë° LoadBalancer ì •ë¦¬ ì‹œì‘..."

          # ëª¨ë“  Ingress ì‚­ì œ
          kubectl get ingress -A -o json 2>/dev/null | jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl patch ingress $name -n $ns -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete ingress $name -n $ns --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # LoadBalancer íƒ€ì… Service ì‚­ì œ
          kubectl get svc -A -o json 2>/dev/null | jq -r '.items[] | select(.spec.type=="LoadBalancer") | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl delete svc $name -n $ns --timeout=60s 2>/dev/null || true
          done

          echo "âœ… Ingress ë° LoadBalancer ì •ë¦¬ ì™„ë£Œ"

      - name: Force Delete ALB and Target Groups
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 5
        run: |
          echo "ğŸ§¹ ALB ë° Target Group ê°•ì œ ì‚­ì œ..."

          # petclinic ê´€ë ¨ ALB ê°•ì œ ì‚­ì œ
          for alb_arn in $(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'petclinic') || contains(LoadBalancerName, 'k8s') || contains(LoadBalancerName, 'argocd')].LoadBalancerArn" --output text 2>/dev/null); do
            echo "  ì‚­ì œ ì¤‘: $alb_arn"
            # Listener ë¨¼ì € ì‚­ì œ
            for listener_arn in $(aws elbv2 describe-listeners --load-balancer-arn $alb_arn --query 'Listeners[*].ListenerArn' --output text 2>/dev/null); do
              aws elbv2 delete-listener --listener-arn $listener_arn 2>/dev/null || true
            done
            # ALB ì‚­ì œ
            aws elbv2 delete-load-balancer --load-balancer-arn $alb_arn 2>/dev/null || true
          done

          echo "â³ ALB ì‚­ì œ ëŒ€ê¸° (30ì´ˆ)..."
          sleep 30

          # ê³ ì•„ Target Group ì‚­ì œ
          echo "ğŸ§¹ ê³ ì•„ Target Group ì‚­ì œ..."
          for tg_arn in $(aws elbv2 describe-target-groups --query "TargetGroups[?contains(TargetGroupName, 'k8s') || contains(TargetGroupName, 'petclinic')].TargetGroupArn" --output text 2>/dev/null); do
            echo "  ì‚­ì œ ì¤‘: $tg_arn"
            aws elbv2 delete-target-group --target-group-arn $tg_arn 2>/dev/null || true
          done

          echo "âœ… ALB ë° Target Group ì •ë¦¬ ì™„ë£Œ"

      - name: Wait for ALB Deletion
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 5
        run: |
          echo "â³ AWS ë¡œë“œë°¸ëŸ°ì„œ ì‚­ì œ í™•ì¸..."

          # ALB ì‚­ì œ í™•ì¸ (ìµœëŒ€ 5ë¶„ ëŒ€ê¸°)
          for i in {1..30}; do
            ALB_COUNT=$(aws elbv2 describe-load-balancers --query "LoadBalancers[?contains(LoadBalancerName, 'k8s') || contains(LoadBalancerName, 'argocd') || contains(LoadBalancerName, 'petclinic')].LoadBalancerArn" --output text 2>/dev/null | wc -w || echo "0")
            if [ "$ALB_COUNT" -eq 0 ]; then
              echo "âœ… ëª¨ë“  ALB ì‚­ì œ ì™„ë£Œ"
              break
            fi
            echo "  ëŒ€ê¸° ì¤‘... ($i/30) - ë‚¨ì€ ALB: $ALB_COUNT"
            sleep 10
          done

      - name: Pre-Cleanup Complete
        run: echo "âœ… AWS Pre-Cleanup ì™„ë£Œ"

  # ============================================================================
  # GCP Pre-Cleanup (ìŠ¹ì¸ í›„, GCP ì„ íƒ ì‹œ)
  # ============================================================================
  gcp-pre-cleanup:
    name: 'GCP Pre-Cleanup'
    needs: [notify-approval]
    if: github.event.inputs.cloud == 'gcp'
    runs-on: ubuntu-latest
    environment: production  # ğŸ‘ˆ ìŠ¹ì¸ ì—†ìœ¼ë©´ ì—¬ê¸°ì„œ ëŒ€ê¸°
    timeout-minutes: 10
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: github-actions@${{ env.GCP_PROJECT_ID }}.iam.gserviceaccount.com

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Install kubectl
        run: |
          curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: Configure kubectl
        id: configure-kubectl
        continue-on-error: true
        run: |
          if gcloud container clusters describe ${{ env.GCP_CLUSTER_NAME }} --region ${{ env.GCP_REGION }} 2>/dev/null; then
            gcloud container clusters get-credentials ${{ env.GCP_CLUSTER_NAME }} \
              --region ${{ env.GCP_REGION }} \
              --project ${{ env.GCP_PROJECT_ID }}
            echo "âœ… GKE í´ëŸ¬ìŠ¤í„° ì—°ê²°: ${{ env.GCP_CLUSTER_NAME }}"
            echo "cluster_exists=true" >> $GITHUB_OUTPUT
          else
            echo "âš ï¸ GKE í´ëŸ¬ìŠ¤í„° ì—†ìŒ - Pre-cleanup ìŠ¤í‚µ"
            echo "cluster_exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Cleanup ArgoCD Applications
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 2
        run: |
          echo "ğŸ§¹ ArgoCD ì •ë¦¬ ì‹œì‘..."

          kubectl get applications -n argocd -o name 2>/dev/null | while read app; do
            kubectl patch $app -n argocd -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete $app -n argocd --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          echo "âœ… ArgoCD ì •ë¦¬ ì™„ë£Œ"

      - name: Cleanup Ingress and LoadBalancer Services
        if: steps.configure-kubectl.outputs.cluster_exists == 'true'
        continue-on-error: true
        timeout-minutes: 2
        run: |
          echo "ğŸ§¹ Ingress ë° LoadBalancer ì •ë¦¬ ì‹œì‘..."

          # ëª¨ë“  Ingress ì‚­ì œ
          kubectl get ingress -A -o json 2>/dev/null | jq -r '.items[] | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl patch ingress $name -n $ns -p '{"metadata":{"finalizers":null}}' --type=merge 2>/dev/null || true
            kubectl delete ingress $name -n $ns --force --grace-period=0 --timeout=30s 2>/dev/null || true
          done

          # LoadBalancer íƒ€ì… Service ì‚­ì œ
          kubectl get svc -A -o json 2>/dev/null | jq -r '.items[] | select(.spec.type=="LoadBalancer") | "\(.metadata.namespace) \(.metadata.name)"' | while read ns name; do
            [ -z "$ns" ] && continue
            kubectl delete svc $name -n $ns --timeout=60s 2>/dev/null || true
          done

          echo "âœ… Ingress ë° LoadBalancer ì •ë¦¬ ì™„ë£Œ"

      - name: Pre-Cleanup Complete
        run: echo "âœ… GCP Pre-Cleanup ì™„ë£Œ"

  # ============================================================================
  # Terraform Destroy (ìŠ¹ì¸ ë° Pre-Cleanup í›„ ì‹¤í–‰)
  # ============================================================================
  destroy:
    name: 'Terraform Destroy'
    needs: [notify-approval, aws-pre-cleanup, gcp-pre-cleanup]
    if: always() && needs.notify-approval.result == 'success'
    runs-on: ubuntu-latest
    timeout-minutes: 60

    defaults:
      run:
        working-directory: ${{ github.event.inputs.cloud }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      # AWS ì¸ì¦
      - name: Configure AWS credentials
        if: github.event.inputs.cloud == 'aws'
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      # GCP ì¸ì¦
      - name: Authenticate to Google Cloud
        if: github.event.inputs.cloud == 'gcp'
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ env.GCP_WORKLOAD_IDENTITY_PROVIDER }}
          service_account: github-actions@${{ env.GCP_PROJECT_ID }}.iam.gserviceaccount.com

      - name: Set up Cloud SDK
        if: github.event.inputs.cloud == 'gcp'
        uses: google-github-actions/setup-gcloud@v2
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: ${{ env.TF_VERSION }}
          terraform_wrapper: false

      - name: Setup Terragrunt
        run: |
          wget -q https://github.com/gruntwork-io/terragrunt/releases/download/v${{ env.TG_VERSION }}/terragrunt_linux_amd64
          chmod +x terragrunt_linux_amd64
          sudo mv terragrunt_linux_amd64 /usr/local/bin/terragrunt

      # SSH Key (AWS ì „ìš©)
      - name: Create SSH Key
        if: github.event.inputs.cloud == 'aws'
        run: |
          mkdir -p keys
          echo "${{ secrets.SSH_PUBLIC_KEY }}" > keys/test.pub

      # Destroy Compute (EKS/GKE ë¨¼ì € ì‚­ì œ - ë‚´ë¶€ ë¦¬ì†ŒìŠ¤ ìë™ ì •ë¦¬)
      - name: Destroy Compute
        if: github.event.inputs.layer == 'all' || github.event.inputs.layer == 'compute'
        continue-on-error: true
        timeout-minutes: 30
        env:
          TF_VAR_db_password: ${{ secrets.TF_VAR_db_password }}
        run: |
          echo "ğŸ—‘ï¸ Compute Layer Destroy (EKS/GKE ë¨¼ì € ì‚­ì œ)..."
          cd compute && terragrunt destroy --terragrunt-non-interactive -auto-approve || true

      # Destroy Bootstrap (EKS ì‚­ì œ í›„ ì‹¤í–‰ - ArgoCD ë“± ë‚´ë¶€ ë¦¬ì†ŒìŠ¤ëŠ” ì´ë¯¸ ì •ë¦¬ë¨)
      - name: Destroy Bootstrap
        if: github.event.inputs.layer == 'all' || github.event.inputs.layer == 'bootstrap'
        continue-on-error: true
        timeout-minutes: 15
        env:
          TF_VAR_db_password: ${{ secrets.TF_VAR_db_password }}
        run: |
          echo "ğŸ—‘ï¸ Bootstrap Layer Destroy..."
          cd bootstrap && terragrunt destroy --terragrunt-non-interactive -auto-approve || true

      # Destroy Foundation
      - name: Destroy Foundation
        if: github.event.inputs.layer == 'all' || github.event.inputs.layer == 'foundation'
        continue-on-error: true
        timeout-minutes: 15
        env:
          TF_VAR_db_password: ${{ secrets.TF_VAR_db_password }}
        run: |
          echo "ğŸ—‘ï¸ Foundation Layer Destroy..."
          cd foundation && terragrunt destroy --terragrunt-non-interactive -auto-approve || true

      - name: Destroy Complete
        run: |
          echo "=============================================="
          echo "ğŸ‰ Terraform Destroy ì™„ë£Œ!"
          echo "=============================================="
          echo "Cloud: ${{ github.event.inputs.cloud }}"
          echo "Layer: ${{ github.event.inputs.layer }}"

  # ============================================
  # Slack ì•Œë¦¼ - ì™„ë£Œ
  # ============================================
  notify-complete:
    needs: [destroy]
    if: always()
    runs-on: ubuntu-latest
    steps:
      - name: Send Slack Notification - Complete
        uses: slackapi/slack-github-action@v1.26.0
        with:
          payload: |
            {
              "blocks": [
                {
                  "type": "header",
                  "text": {
                    "type": "plain_text",
                    "text": "${{ needs.destroy.result == 'success' && 'âœ… Terraform Destroy ì„±ê³µ' || 'âŒ Terraform Destroy ì‹¤íŒ¨' }}",
                    "emoji": true
                  }
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*Cloud:*\n${{ github.event.inputs.cloud }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*Layer:*\n${{ github.event.inputs.layer }}"
                    }
                  ]
                },
                {
                  "type": "section",
                  "fields": [
                    {
                      "type": "mrkdwn",
                      "text": "*ê²°ê³¼:*\n${{ needs.destroy.result }}"
                    },
                    {
                      "type": "mrkdwn",
                      "text": "*ì‹¤í–‰ì:*\n${{ github.actor }}"
                    }
                  ]
                },
                {
                  "type": "actions",
                  "elements": [
                    {
                      "type": "button",
                      "text": {
                        "type": "plain_text",
                        "text": "ìƒì„¸ ë¡œê·¸ ë³´ê¸°",
                        "emoji": true
                      },
                      "url": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"
                    }
                  ]
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_WEBHOOK_TYPE: INCOMING_WEBHOOK
